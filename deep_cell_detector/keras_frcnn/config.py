from keras import backend as K
#---------------note by wwk----------line 27-28 are  commented  
#---------!!!!!!!!!!when switching base network, need change 3 parameters: self.network, self.rpn_stride, self.model_path
class Config:

	def __init__(self):

		self.verbose = True

		self.network = 'vgg'

		# setting for data augmentation
		self.use_horizontal_flips = True
		self.use_vertical_flips = True
		self.rot_90 = True

		# anchor box scales  #----note wwk---this scale should be consistant with the resized image(self.im_size). when make prediction on large image,if you resize the 1952*1952 to 640*640, you get poor prediction because cell are shrinked.
		self.anchor_box_scales = [40, 60, 80]
        #---note wwk----- train and test should be consistent, train image size/self.im_size(train)=predict image size/self.im_size(predict)
		# anchor box ratios
		self.anchor_box_ratios = [[1, 1], [1, 2], [2, 1]]

		# size to resize the smallest side of the image
		self.train_img_size=256
		self.im_size = 512

		# image channel-wise mean to subtract
		# self.img_channel_mean = [103.939, 116.779, 123.68]
		# self.img_scaling_factor = 1.0
		#----------note wwk-------this value is calculated on all train images
		self.img_mean = 0.5728
		# number of ROIs at once
		self.num_rois = 4

		# stride at the RPN (this depends on the network configuration)  #--------for resnet50, the the image size also shrink 16 times with current strides
		self.rpn_stride = 16#----------note wwk--------for vgg, max-pooling 4times, so this value should be 16, for recover the image size. see data_generators

		self.balanced_classes = False

		# scaling the stdev
		self.std_scaling = 4.0
		self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

		# overlaps for RPN
		self.rpn_min_overlap = 0.3 #----note wwk---- these two are used in data_generators, compare anchor box and ground truth box
		self.rpn_max_overlap = 0.7 # iou>rpn_max_overlap:positive anchor box   iou<rpn_min_overlap:negative anchor box 

		# overlaps for classifier ROIs
		self.classifier_min_overlap = 0.2 #----note wwk--- these two are used in roi_helpers (calc_iou), compare region proposal(converted to ROI and non-maximalsuppression) with ground truth
		self.classifier_max_overlap = 0.6 # max_overlap>iou>=min_overlap:background  iou>max_overlap:positive roi

		# placeholder for the class mapping, automatically generated by the parser
		self.class_mapping = None

		#location of pretrained weights for the base network 
		# weight files can be found at:
		# https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5
		# https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

		self.model_path = 'model_frcnn_nmumg_ellipse.vgg.hdf5'
